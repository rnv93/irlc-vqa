{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanyam/miniconda3/envs/py2t3/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from dataset import Dictionary, HMQAFeatureDataset\n",
    "from model import SoftCount\n",
    "from config import *\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import cPickle as pkl\n",
    "import json\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dictionary from data/dictionary.pkl\n"
     ]
    }
   ],
   "source": [
    "dictionary = Dictionary.load_from_file('data/dictionary.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading features from train hdf5 file\n",
      "CPU times: user 3.92 s, sys: 1min 32s, total: 1min 36s\n",
      "Wall time: 3min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('loading features from train hdf5 file')\n",
    "train_h5_loc = './data/train36.hdf5'\n",
    "with h5py.File(train_h5_loc, 'r') as hf:\n",
    "    train_image_features = np.array(hf.get('image_features'))\n",
    "    train_spatials_features = np.array(hf.get('spatial_features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import HMQAFeatureDataset\n",
    "\n",
    "hmqa_train_dset = HMQAFeatureDataset(\n",
    "    img_id2hqma_idx = pkl.load(open(\"./data/train36_imgid2idx.pkl\", \"rb\")),\n",
    "    image_features = train_image_features, \n",
    "    spatial_features = train_spatials_features, \n",
    "    qid2count = json.load(open(\"./data/how_many_qa/qid2count.json\", \"rb\")), \n",
    "    qid2count2score = json.load(open(\"./data/how_many_qa/qid2count2score.json\", \"rb\")), \n",
    "    name=\"train\", \n",
    "    dictionary=dictionary\n",
    ")\n",
    "del HMQAFeatureDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83642"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hmqa_train_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45546"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([x[\"image_id\"] for x in hmqa_train_dset.entries]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading features from val hdf5 file\n",
      "CPU times: user 2.41 s, sys: 57.7 s, total: 1min\n",
      "Wall time: 1min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('loading features from val hdf5 file')\n",
    "val_h5_loc = './data/val36.hdf5'\n",
    "with h5py.File(val_h5_loc, 'r') as hf:\n",
    "    val_image_features = np.array(hf.get('image_features'))\n",
    "    val_spatials_features = np.array(hf.get('spatial_features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_image_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import HMQAFeatureDataset\n",
    "\n",
    "hmqa_dev_dset = HMQAFeatureDataset(\n",
    "    img_id2hqma_idx = pkl.load(open(\"./data/val36_imgid2idx.pkl\", \"rb\")),\n",
    "    image_features = val_image_features, \n",
    "    spatial_features = val_spatials_features, \n",
    "    qid2count = json.load(open(\"./data/how_many_qa/qid2count.json\", \"rb\")), \n",
    "    qid2count2score = json.load(open(\"./data/how_many_qa/qid2count2score.json\", \"rb\")), \n",
    "    name=\"dev\", \n",
    "    dictionary=dictionary\n",
    ")\n",
    "\n",
    "hmqa_test_dset = HMQAFeatureDataset(\n",
    "    img_id2hqma_idx = pkl.load(open(\"./data/val36_imgid2idx.pkl\", \"rb\")),\n",
    "    image_features = val_image_features, \n",
    "    spatial_features = val_spatials_features, \n",
    "    qid2count = json.load(open(\"./data/how_many_qa/qid2count.json\", \"rb\")), \n",
    "    qid2count2score = json.load(open(\"./data/how_many_qa/qid2count2score.json\", \"rb\")), \n",
    "    name=\"test\", \n",
    "    dictionary=dictionary\n",
    ")\n",
    "del HMQAFeatureDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17714, 5000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hmqa_dev_dset), len(hmqa_test_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "hmqa_train_loader = DataLoader(hmqa_train_dset, 64, shuffle=True, num_workers=1)\n",
    "hmqa_dev_loader = DataLoader(hmqa_dev_dset, 64, shuffle=True, num_workers=1)\n",
    "hmqa_test_loader = DataLoader(hmqa_test_dset, 64, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, hmqa_loader):\n",
    "    \n",
    "    all_acc = []\n",
    "    all_se = []\n",
    "    for i, (v_emb, b, q, c, c2s) in enumerate(hmqa_loader):\n",
    "        v_emb = Variable(v_emb)\n",
    "        q = Variable(q)\n",
    "        c = Variable(c).float()\n",
    "        \n",
    "        if USE_CUDA:\n",
    "            v_emb = v_emb.cuda()\n",
    "            q = q.cuda()\n",
    "            c = c.cuda()\n",
    "\n",
    "        pred = model(v_emb, q)\n",
    "        \n",
    "        nearest_pred = (pred + 0.5).long().clamp(0, 20)\n",
    "        for one_c, one_c2s, one_pred in zip(c, c2s, nearest_pred):\n",
    "            one_c = one_c.cpu().data\n",
    "            one_pred = one_pred.cpu().data\n",
    "            \n",
    "            all_se.append((one_c - one_pred.float()) ** 2)\n",
    "            all_acc.append(one_c2s[one_pred])\n",
    "    \n",
    "    acc = torch.stack(all_acc).mean()\n",
    "    rmse = torch.stack(all_se).mean() ** 0.5\n",
    "    \n",
    "    return acc, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialising with glove embeddings\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "from model import SoftCount\n",
    "model = SoftCount()\n",
    "del SoftCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE_CUDA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SoftCount(\n",
       "  (ques_parser): QuestionParser(\n",
       "    (embd): Embedding(20159, 300, padding_idx=20158)\n",
       "    (rnn): GRU(300, 1024)\n",
       "    (dropout): Dropout(p=0.1)\n",
       "  )\n",
       "  (f): ScoringFunction(\n",
       "    (v_drop): Dropout(p=0.1)\n",
       "    (q_drop): Dropout(p=0.1)\n",
       "    (v_proj): FCNet(\n",
       "      (main): Sequential(\n",
       "        (0): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (q_proj): FCNet(\n",
       "      (main): Sequential(\n",
       "        (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1)\n",
       "  )\n",
       "  (W): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.00298000009059906, 15.40445390138839)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc, test_rmse = evaluate(model, hmqa_test_loader)\n",
    "test_acc, test_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0, i = 0, loss = 14.602848053, huber = 14.602848053, mse = 238.237670898\n",
      "epoch = 0, i = 100, loss = 1.5097117424, huber = 1.5097117424, mse = 7.86944198608\n",
      "epoch = 0, i = 200, loss = 1.23882031441, huber = 1.23882031441, mse = 8.64920711517\n",
      "evaluating model on train, dev and test...\n",
      "test_acc: 0.377700001514, test_rmse: 3.05054093564\n",
      "epoch = 1, i = 0, loss = 0.956357479095, huber = 0.956357479095, mse = 6.0752196312\n",
      "epoch = 1, i = 100, loss = 1.71862578392, huber = 1.71862578392, mse = 11.6909618378\n",
      "epoch = 1, i = 200, loss = 1.71545946598, huber = 1.71545946598, mse = 10.1975259781\n",
      "evaluating model on train, dev and test...\n",
      "test_acc: 0.342000001669, test_rmse: 2.90926107457\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    for i, (v_emb, b, q, c, _) in enumerate(hmqa_dev_loader):\n",
    "        v_emb = Variable(v_emb)\n",
    "        q = Variable(q)\n",
    "        c = Variable(c).float()\n",
    "        \n",
    "        if USE_CUDA:\n",
    "            v_emb = v_emb.cuda()\n",
    "            q = q.cuda()\n",
    "            c = c.cuda()\n",
    "\n",
    "        pred = model(v_emb, q)\n",
    "        huber_loss = F.smooth_l1_loss(pred, c)\n",
    "        mse_loss =  F.mse_loss(pred, c)\n",
    "        loss =  huber_loss # + 0.1 * mse_loss\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(\"epoch = {}, i = {}, loss = {}, huber = {}, mse = {}\".format(epoch, i, loss.data[0], \n",
    "                                                                              huber_loss.data[0], mse_loss.data[0]))\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), 0.25)\n",
    "        opt.step()\n",
    "    \n",
    "    \n",
    "    print(\"evaluating model on train, dev and test...\")\n",
    "    \n",
    "#     train_acc, train_rmse = evaluate(model, hmqa_train_loader)\n",
    "#     print(\"train_acc: {}, train_rmse: {}\".format(train_acc, train_rmse))\n",
    "    \n",
    "    model.eval()\n",
    "#     dev_acc, dev_rmse = evaluate(model, hmqa_dev_loader)\n",
    "#     print(\"dev_acc: {}, dev_rmse: {}\".format(dev_acc, dev_rmse))\n",
    "    test_acc, test_rmse = evaluate(model, hmqa_test_loader)\n",
    "    print(\"test_acc: {}, test_rmse: {}\".format(test_acc, test_rmse))\n",
    "    model.train()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.ques_parser.state_dict(), \"soft_count_ques_parser.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.f.state_dict(), \"soft_count_f.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"soft_count.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import RhoScorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RhoScorer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.from_numpy(np.array([\n",
    "    [ #start 1st batch\n",
    "        [0,0, 2, 2],\n",
    "        [1,1, 3,3],\n",
    "        [2,2,3,3],\n",
    "    ] # 1st batch\n",
    "]\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "  0  0  2  2\n",
       "  1  1  3  3\n",
       "  2  2  3  3\n",
       "[torch.LongTensor of size 1x3x4]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_ij, b_ji, iou, o_ij, o_ji = rs.get_spatials(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       "  1.0000  0.1429  0.0000\n",
       "  0.1429  1.0000  0.2500\n",
       "  0.0000  0.2500  1.0000\n",
       " [torch.FloatTensor of size 3x3], \n",
       "  1.0000  0.2500  0.0000\n",
       "  0.2500  1.0000  1.0000\n",
       "  0.0000  0.2500  1.0000\n",
       " [torch.FloatTensor of size 3x3], \n",
       "  1.0000  0.2500  0.0000\n",
       "  0.2500  1.0000  0.2500\n",
       "  0.0000  1.0000  1.0000\n",
       " [torch.FloatTensor of size 3x3])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou[0, :, :, 0], o_ij[0, :, :, 0], o_ji[0, :, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
