{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanyam/miniconda3/envs/py2t3/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from dataset import Dictionary, HMQAFeatureDataset\n",
    "from model import SoftCount\n",
    "from config import *\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import cPickle as pkl\n",
    "import json\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dictionary from data/dictionary.pkl\n"
     ]
    }
   ],
   "source": [
    "dictionary = Dictionary.load_from_file('data/dictionary.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading features from train hdf5 file\n",
      "CPU times: user 3.92 s, sys: 1min 32s, total: 1min 36s\n",
      "Wall time: 3min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('loading features from train hdf5 file')\n",
    "train_h5_loc = './data/train36.hdf5'\n",
    "with h5py.File(train_h5_loc, 'r') as hf:\n",
    "    train_image_features = np.array(hf.get('image_features'))\n",
    "    train_spatials_features = np.array(hf.get('spatial_features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import HMQAFeatureDataset\n",
    "\n",
    "hmqa_train_dset = HMQAFeatureDataset(\n",
    "    img_id2hqma_idx = pkl.load(open(\"./data/train36_imgid2idx.pkl\", \"rb\")),\n",
    "    image_features = train_image_features, \n",
    "    spatial_features = train_spatials_features, \n",
    "    qid2count = json.load(open(\"./data/how_many_qa/qid2count.json\", \"rb\")), \n",
    "    qid2count2score = json.load(open(\"./data/how_many_qa/qid2count2score.json\", \"rb\")), \n",
    "    name=\"train\", \n",
    "    dictionary=dictionary\n",
    ")\n",
    "del HMQAFeatureDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83642"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hmqa_train_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45546"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([x[\"image_id\"] for x in hmqa_train_dset.entries]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading features from val hdf5 file\n",
      "CPU times: user 2.41 s, sys: 57.7 s, total: 1min\n",
      "Wall time: 1min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('loading features from val hdf5 file')\n",
    "val_h5_loc = './data/val36.hdf5'\n",
    "with h5py.File(val_h5_loc, 'r') as hf:\n",
    "    val_image_features = np.array(hf.get('image_features'))\n",
    "    val_spatials_features = np.array(hf.get('spatial_features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_image_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import HMQAFeatureDataset\n",
    "\n",
    "hmqa_dev_dset = HMQAFeatureDataset(\n",
    "    img_id2hqma_idx = pkl.load(open(\"./data/val36_imgid2idx.pkl\", \"rb\")),\n",
    "    image_features = val_image_features, \n",
    "    spatial_features = val_spatials_features, \n",
    "    qid2count = json.load(open(\"./data/how_many_qa/qid2count.json\", \"rb\")), \n",
    "    qid2count2score = json.load(open(\"./data/how_many_qa/qid2count2score.json\", \"rb\")), \n",
    "    name=\"dev\", \n",
    "    dictionary=dictionary\n",
    ")\n",
    "\n",
    "hmqa_test_dset = HMQAFeatureDataset(\n",
    "    img_id2hqma_idx = pkl.load(open(\"./data/val36_imgid2idx.pkl\", \"rb\")),\n",
    "    image_features = val_image_features, \n",
    "    spatial_features = val_spatials_features, \n",
    "    qid2count = json.load(open(\"./data/how_many_qa/qid2count.json\", \"rb\")), \n",
    "    qid2count2score = json.load(open(\"./data/how_many_qa/qid2count2score.json\", \"rb\")), \n",
    "    name=\"test\", \n",
    "    dictionary=dictionary\n",
    ")\n",
    "del HMQAFeatureDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17714, 5000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hmqa_dev_dset), len(hmqa_test_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "hmqa_train_loader = DataLoader(hmqa_train_dset, 64, shuffle=True, num_workers=1)\n",
    "hmqa_dev_loader = DataLoader(hmqa_dev_dset, 64, shuffle=True, num_workers=1)\n",
    "hmqa_test_loader = DataLoader(hmqa_test_dset, 64, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, hmqa_loader):\n",
    "    \n",
    "    all_acc = []\n",
    "    all_se = []\n",
    "    for i, (v_emb, b, q, c, c2s) in enumerate(hmqa_loader):\n",
    "        v_emb = Variable(v_emb)\n",
    "        q = Variable(q)\n",
    "        c = Variable(c).float()\n",
    "        \n",
    "        if USE_CUDA:\n",
    "            v_emb = v_emb.cuda()\n",
    "            q = q.cuda()\n",
    "            c = c.cuda()\n",
    "\n",
    "        pred = model(v_emb, q)\n",
    "        \n",
    "        nearest_pred = (pred + 0.5).long().clamp(0, 20)\n",
    "        for one_c, one_c2s, one_pred in zip(c, c2s, nearest_pred):\n",
    "            one_c = one_c.cpu().data\n",
    "            one_pred = one_pred.cpu().data\n",
    "            \n",
    "            all_se.append((one_c - one_pred.float()) ** 2)\n",
    "            all_acc.append(one_c2s[one_pred])\n",
    "    \n",
    "    acc = torch.stack(all_acc).mean()\n",
    "    rmse = torch.stack(all_se).mean() ** 0.5\n",
    "    \n",
    "    return acc, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialising with glove embeddings\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "from model import SoftCount\n",
    "model = SoftCount()\n",
    "del SoftCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE_CUDA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SoftCount(\n",
       "  (ques_parser): QuestionParser(\n",
       "    (embd): Embedding(20159, 300, padding_idx=20158)\n",
       "    (rnn): GRU(300, 1024)\n",
       "    (dropout): Dropout(p=0.1)\n",
       "  )\n",
       "  (f): ScoringFunction(\n",
       "    (v_drop): Dropout(p=0.1)\n",
       "    (q_drop): Dropout(p=0.1)\n",
       "    (v_proj): FCNet(\n",
       "      (main): Sequential(\n",
       "        (0): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (q_proj): FCNet(\n",
       "      (main): Sequential(\n",
       "        (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1)\n",
       "  )\n",
       "  (W): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.00298000009059906, 15.404155283559044)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc, test_rmse = evaluate(model, hmqa_test_loader)\n",
    "test_acc, test_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0, i = 0, loss = 0.550097882748, huber = 0.550097882748, mse = 3.87832069397\n",
      "epoch = 0, i = 100, loss = 0.324541091919, huber = 0.324541091919, mse = 0.77025103569\n",
      "epoch = 0, i = 200, loss = 0.413172006607, huber = 0.413172006607, mse = 1.46421694756\n",
      "epoch = 0, i = 300, loss = 0.538510084152, huber = 0.538510084152, mse = 2.73510503769\n",
      "epoch = 0, i = 400, loss = 0.418540328741, huber = 0.418540328741, mse = 1.4878578186\n",
      "epoch = 0, i = 500, loss = 0.552978396416, huber = 0.552978396416, mse = 2.26761984825\n",
      "epoch = 0, i = 600, loss = 0.399310112, huber = 0.399310112, mse = 2.21824645996\n",
      "epoch = 0, i = 700, loss = 0.459556460381, huber = 0.459556460381, mse = 1.49132847786\n",
      "epoch = 0, i = 800, loss = 0.519453048706, huber = 0.519453048706, mse = 1.84664309025\n",
      "epoch = 0, i = 900, loss = 0.465825378895, huber = 0.465825378895, mse = 1.76220428944\n",
      "epoch = 0, i = 1000, loss = 0.606564640999, huber = 0.606564640999, mse = 4.46711158752\n",
      "epoch = 0, i = 1100, loss = 0.403664261103, huber = 0.403664261103, mse = 1.30054330826\n",
      "epoch = 0, i = 1200, loss = 0.321386069059, huber = 0.321386069059, mse = 0.765318274498\n",
      "epoch = 0, i = 1300, loss = 0.371942490339, huber = 0.371942490339, mse = 1.06465363503\n",
      "evaluating model on train, dev and test...\n",
      "test_acc: 0.492400001574, test_rmse: 2.39073210544\n",
      "epoch = 1, i = 0, loss = 0.840094685555, huber = 0.840094685555, mse = 6.97358894348\n",
      "epoch = 1, i = 100, loss = 0.360145509243, huber = 0.360145509243, mse = 1.14291834831\n",
      "epoch = 1, i = 200, loss = 0.206201076508, huber = 0.206201076508, mse = 0.496559143066\n",
      "epoch = 1, i = 300, loss = 0.308097988367, huber = 0.308097988367, mse = 0.840111374855\n",
      "epoch = 1, i = 400, loss = 0.266017079353, huber = 0.266017079353, mse = 0.637104153633\n",
      "epoch = 1, i = 500, loss = 0.375430345535, huber = 0.375430345535, mse = 0.971576213837\n",
      "epoch = 1, i = 600, loss = 0.405089139938, huber = 0.405089139938, mse = 1.11176133156\n",
      "epoch = 1, i = 700, loss = 0.602277636528, huber = 0.602277636528, mse = 2.47417449951\n",
      "epoch = 1, i = 800, loss = 0.4370880723, huber = 0.4370880723, mse = 1.236115098\n",
      "epoch = 1, i = 900, loss = 0.430779606104, huber = 0.430779606104, mse = 1.66634535789\n",
      "epoch = 1, i = 1000, loss = 0.473167479038, huber = 0.473167479038, mse = 1.4955073595\n",
      "epoch = 1, i = 1100, loss = 0.496063411236, huber = 0.496063411236, mse = 1.55630195141\n",
      "epoch = 1, i = 1200, loss = 0.508312404156, huber = 0.508312404156, mse = 1.82663285732\n",
      "epoch = 1, i = 1300, loss = 0.643235325813, huber = 0.643235325813, mse = 2.49034428596\n",
      "evaluating model on train, dev and test...\n",
      "test_acc: 0.489880001605, test_rmse: 2.38071417856\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    for i, (v_emb, b, q, c, _) in enumerate(hmqa_train_loader):\n",
    "        v_emb = Variable(v_emb)\n",
    "        q = Variable(q)\n",
    "        c = Variable(c).float()\n",
    "        \n",
    "        if USE_CUDA:\n",
    "            v_emb = v_emb.cuda()\n",
    "            q = q.cuda()\n",
    "            c = c.cuda()\n",
    "\n",
    "        pred = model(v_emb, q)\n",
    "        huber_loss = F.smooth_l1_loss(pred, c)\n",
    "        mse_loss =  F.mse_loss(pred, c)\n",
    "        loss =  huber_loss # + 0.1 * mse_loss\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(\"epoch = {}, i = {}, loss = {}, huber = {}, mse = {}\".format(epoch, i, loss.data[0], \n",
    "                                                                              huber_loss.data[0], mse_loss.data[0]))\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), 0.25)\n",
    "        opt.step()\n",
    "    \n",
    "    \n",
    "    print(\"evaluating model on train, dev and test...\")\n",
    "    \n",
    "#     train_acc, train_rmse = evaluate(model, hmqa_train_loader)\n",
    "#     print(\"train_acc: {}, train_rmse: {}\".format(train_acc, train_rmse))\n",
    "    \n",
    "    model.eval()\n",
    "#     dev_acc, dev_rmse = evaluate(model, hmqa_dev_loader)\n",
    "#     print(\"dev_acc: {}, dev_rmse: {}\".format(dev_acc, dev_rmse))\n",
    "    test_acc, test_rmse = evaluate(model, hmqa_test_loader)\n",
    "    print(\"test_acc: {}, test_rmse: {}\".format(test_acc, test_rmse))\n",
    "    model.train()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
