{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanyam/miniconda3/envs/py2t3/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from dataset import Dictionary, HMQAFeatureDataset\n",
    "from model import SoftCount\n",
    "from config import *\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import cPickle as pkl\n",
    "import json\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dictionary from data/dictionary.pkl\n"
     ]
    }
   ],
   "source": [
    "dictionary = Dictionary.load_from_file('data/dictionary.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading features from train hdf5 file\n",
      "CPU times: user 3.92 s, sys: 1min 32s, total: 1min 36s\n",
      "Wall time: 3min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('loading features from train hdf5 file')\n",
    "train_h5_loc = './data/train36.hdf5'\n",
    "with h5py.File(train_h5_loc, 'r') as hf:\n",
    "    train_image_features = np.array(hf.get('image_features'))\n",
    "    train_spatials_features = np.array(hf.get('spatial_features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import HMQAFeatureDataset\n",
    "\n",
    "hmqa_train_dset = HMQAFeatureDataset(\n",
    "    img_id2hqma_idx = pkl.load(open(\"./data/train36_imgid2idx.pkl\", \"rb\")),\n",
    "    image_features = train_image_features, \n",
    "    spatial_features = train_spatials_features, \n",
    "    qid2count = json.load(open(\"./data/how_many_qa/qid2count.json\", \"rb\")), \n",
    "    qid2count2score = json.load(open(\"./data/how_many_qa/qid2count2score.json\", \"rb\")), \n",
    "    name=\"train\", \n",
    "    dictionary=dictionary\n",
    ")\n",
    "del HMQAFeatureDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83642"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hmqa_train_dset)z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45546"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([x[\"image_id\"] for x in hmqa_train_dset.entries]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading features from val hdf5 file\n",
      "CPU times: user 1.78 s, sys: 19.9 s, total: 21.7 s\n",
      "Wall time: 21.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('loading features from val hdf5 file')\n",
    "val_h5_loc = './data/val36.hdf5'\n",
    "with h5py.File(val_h5_loc, 'r') as hf:\n",
    "    val_image_features = np.array(hf.get('image_features'))\n",
    "    val_spatials_features = np.array(hf.get('spatial_features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_image_features)\n",
    "\n",
    "from dataset import HMQAFeatureDataset\n",
    "\n",
    "hmqa_dev_dset = HMQAFeatureDataset(\n",
    "    img_id2hqma_idx = pkl.load(open(\"./data/val36_imgid2idx.pkl\", \"rb\")),\n",
    "    image_features = val_image_features, \n",
    "    spatial_features = val_spatials_features, \n",
    "    qid2count = json.load(open(\"./data/how_many_qa/qid2count.json\", \"rb\")), \n",
    "    qid2count2score = json.load(open(\"./data/how_many_qa/qid2count2score.json\", \"rb\")), \n",
    "    name=\"dev\", \n",
    "    dictionary=dictionary\n",
    ")\n",
    "\n",
    "hmqa_test_dset = HMQAFeatureDataset(\n",
    "    img_id2hqma_idx = pkl.load(open(\"./data/val36_imgid2idx.pkl\", \"rb\")),\n",
    "    image_features = val_image_features, \n",
    "    spatial_features = val_spatials_features, \n",
    "    qid2count = json.load(open(\"./data/how_many_qa/qid2count.json\", \"rb\")), \n",
    "    qid2count2score = json.load(open(\"./data/how_many_qa/qid2count2score.json\", \"rb\")), \n",
    "    name=\"test\", \n",
    "    dictionary=dictionary\n",
    ")\n",
    "del HMQAFeatureDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17714, 5000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hmqa_dev_dset), len(hmqa_test_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# hmqa_train_loader = DataLoader(hmqa_train_dset, 64, shuffle=True, num_workers=1)\n",
    "hmqa_dev_loader = DataLoader(hmqa_dev_dset, 64, shuffle=True, num_workers=1)\n",
    "hmqa_test_loader = DataLoader(hmqa_test_dset, 64, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, hmqa_loader, coeff=1):\n",
    "    \n",
    "    all_acc = []\n",
    "    all_se = []\n",
    "    for i, (v_emb, b, q, c, c2s) in enumerate(hmqa_loader):\n",
    "        v_emb = Variable(v_emb)\n",
    "        b = Variable(b)\n",
    "        q = Variable(q)\n",
    "        c = Variable(c).view(-1).float()\n",
    "        \n",
    "        if USE_CUDA:\n",
    "            v_emb = v_emb.cuda()\n",
    "            b = b.cuda()\n",
    "            q = q.cuda()\n",
    "            c = c.cuda()\n",
    "        \n",
    "        kappa_0, rho = model.compute_vars(v_emb *coeff, b * coeff, q * coeff)\n",
    "        count, greedy_count, P, A, rho = model.take_mc_samples(kappa_0, rho, 1)\n",
    "        \n",
    "#         pred = model(v_emb, q)\n",
    "        \n",
    "#         ret = torch.stack((count.float(), greedy_count.float(), c.float()))\n",
    "#         break\n",
    "    \n",
    "        nearest_pred = (greedy_count + 0.5).long().clamp(0, 20)\n",
    "        for one_c, one_c2s, one_pred in zip(c, c2s, nearest_pred):\n",
    "            one_c = one_c.cpu().data\n",
    "            one_pred = one_pred.cpu().data\n",
    "            \n",
    "#             print(\"one_c = \", one_c, \" and nearest pred = \", one_pred)\n",
    "            \n",
    "            all_se.append((one_c - one_pred.float()) ** 2)\n",
    "            all_acc.append(one_c2s[one_pred])\n",
    "    \n",
    "    acc = torch.stack(all_acc).mean()\n",
    "    rmse = torch.stack(all_se).mean() ** 0.5\n",
    "    \n",
    "    return acc, rmse  #, ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isnan(x):\n",
    "    check = (x != x)\n",
    "    check = check.float().sum().data[0]\n",
    "    return check > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialising with glove embeddings\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "from model import IRLC\n",
    "model = IRLC()\n",
    "del IRLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.ques_parser.load_state_dict(torch.load(\"soft_count_ques_parser.pth\"))\n",
    "# model.f_s.load_state_dict(torch.load(\"soft_count_f.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE_CUDA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IRLC(\n",
       "  (ques_parser): QuestionParser(\n",
       "    (embd): Embedding(20159, 300, padding_idx=20158)\n",
       "    (rnn): GRU(300, 1024)\n",
       "    (dropout): Dropout(p=0.1)\n",
       "  )\n",
       "  (f_s): ScoringFunction(\n",
       "    (v_drop): Dropout(p=0.1)\n",
       "    (q_drop): Dropout(p=0.1)\n",
       "    (v_proj): FCNet(\n",
       "      (main): Sequential(\n",
       "        (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (q_proj): FCNet(\n",
       "      (main): Sequential(\n",
       "        (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1)\n",
       "  )\n",
       "  (W): Linear(in_features=2048, out_features=1, bias=True)\n",
       "  (f_rho): RhoScorer(\n",
       "    (W): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (f_rho): FCNet(\n",
       "      (main): Sequential(\n",
       "        (0): Linear(in_features=17, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=1, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (extra_params): ParameterList(\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.012000000262260438, 17.323631259063443)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc, test_rmse = evaluate(model, hmqa_test_loader)\n",
    "test_acc, test_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0, i = 0, loss = 49.4169654846,\n",
      "epoch = 0, i = 100, loss = 0.959388554096,\n",
      "epoch = 0, i = 200, loss = -0.0486254766583,\n",
      "evaluating model on train, dev and test...\n",
      "test_acc: 0.21298000102, test_rmse: 3.88664379639\n",
      "epoch = 1, i = 0, loss = -0.0153276687488,\n",
      "epoch = 1, i = 100, loss = 0.0428304076195,\n",
      "epoch = 1, i = 200, loss = -0.00206291372888,\n",
      "evaluating model on train, dev and test...\n",
      "test_acc: 0.25372000128, test_rmse: 3.55955053342\n",
      "epoch = 2, i = 0, loss = 0.00610870262608,\n",
      "epoch = 2, i = 100, loss = -0.0264539178461,\n",
      "epoch = 2, i = 200, loss = -0.0316820368171,\n",
      "evaluating model on train, dev and test...\n",
      "test_acc: 0.236320001256, test_rmse: 3.52913587157\n",
      "epoch = 3, i = 0, loss = -0.0172131024301,\n",
      "epoch = 3, i = 100, loss = -0.0302072763443,\n",
      "epoch = 3, i = 200, loss = 0.0261585265398,\n",
      "evaluating model on train, dev and test...\n",
      "test_acc: 0.240760001314, test_rmse: 3.48129286329\n",
      "epoch = 4, i = 0, loss = -0.719782114029,\n",
      "epoch = 4, i = 100, loss = -0.0167286451906,\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    for i, (v_emb, b, q, c, _) in enumerate(hmqa_dev_loader):\n",
    "        v_emb = Variable(v_emb)\n",
    "        b = Variable(b)\n",
    "        q = Variable(q)\n",
    "        c = Variable(c).view(-1).float()\n",
    "        \n",
    "        if USE_CUDA:\n",
    "            v_emb = v_emb.cuda()\n",
    "            q = q.cuda()\n",
    "            c = c.cuda()\n",
    "            b = b.cuda()\n",
    "\n",
    "#         count, greedy_count, P, A, rho = model(v_emb, b, q)\n",
    "        \n",
    "        B, k, _ = v_emb.size()\n",
    "        \n",
    "        kappa_0, rho = model.compute_vars(v_emb, b, q)\n",
    "        if isnan(kappa_0) or isnan(rho) or isnan(model.eps):\n",
    "            raise Exception(\"there are nans here\")\n",
    "            \n",
    "        num_samples = 10\n",
    "        count, greedy_count, P, A, rho = model.take_mc_samples(kappa_0, rho, num_samples)\n",
    "        c_gt = torch.cat([c] * num_samples)\n",
    "        loss = model.get_loss(c_gt, count, greedy_count, P, A, rho)\n",
    "        \n",
    "    \n",
    "        if i % 100 == 0:\n",
    "            print(\"epoch = {}, i = {}, loss = {},\".format(epoch, i, loss.data[0],))\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), 0.25)\n",
    "        opt.step()\n",
    "    \n",
    "    \n",
    "    print(\"evaluating model on train, dev and test...\")\n",
    "    \n",
    "#     train_acc, train_rmse = evaluate(model, hmqa_dev_loader)\n",
    "#     print(\"train_acc: {}, train_rmse: {}\".format(train_acc, train_rmse))\n",
    "    \n",
    "#     model.eval()\n",
    "#     dev_acc, dev_rmse = evaluate(model, hmqa_dev_loader)\n",
    "#     print(\"dev_acc: {}, dev_rmse: {}\".format(dev_acc, dev_rmse))\n",
    "    test_acc, test_rmse = evaluate(model, hmqa_test_loader)\n",
    "    print(\"test_acc: {}, test_rmse: {}\".format(test_acc, test_rmse))\n",
    "#     model.train()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: renormalize the probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "\n",
       "Columns 0 to 12 \n",
       "   36    11     5    32    31    36    12    16    35    36    21    34    29\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    4     3     2     2     4     1     2     1     0     6     5     1     2\n",
       "\n",
       "Columns 13 to 25 \n",
       "   31     1    33    36    36    18    33     0    35     3    34    34    36\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     5     2     3     1     1     1     1     5     1     1     2     2\n",
       "\n",
       "Columns 26 to 38 \n",
       "   36     2    26    33    36    36    17    36    15    22     9    36     2\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    2     4     1     2     4     1     0     5     1     1     2     1     2\n",
       "\n",
       "Columns 39 to 51 \n",
       "   31     8     8    11    33    36    23    36     5     8    25     9     8\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    8     1     2     0    10    14     9     2     1     2     1     5     1\n",
       "\n",
       "Columns 52 to 64 \n",
       "    0    35    29    12    18    31    35     2    36    11    33    25    11\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    1     8     1     8     5     2     5     5     4     2     1     4     4\n",
       "\n",
       "Columns 65 to 77 \n",
       "   20     1    35     1    21     6    36    23    36    34    34     2    30\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    3     2     2     4     1     2     1     0     6     5     1     2     0\n",
       "\n",
       "Columns 78 to 90 \n",
       "    9     2    10    35    35     8    36    10    33     6    34    26    24\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    5     2     3     1     1     1     1     5     1     1     2     2     2\n",
       "\n",
       "Columns 91 to 99 \n",
       "   29    36     1    31    35    31    13    21     1\n",
       "    0     0     0     0     0     0     0     0     0\n",
       "    4     1     2     4     1     0     5     1     1\n",
       "[torch.cuda.FloatTensor of size 3x100 (GPU 0)]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack((count.float(), greedy_count.float(), c_gt.float()))[:, :100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " 1.00000e-02 *\n",
       "   2.6912\n",
       "   2.7500\n",
       "   2.7771\n",
       "   2.8506\n",
       "   2.9212\n",
       "   3.0551\n",
       "   3.1778\n",
       "   3.2342\n",
       "   3.3306\n",
       "   3.5390\n",
       "   3.6401\n",
       "   3.7144\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       " [torch.cuda.FloatTensor of size 37 (GPU 0)], Variable containing:\n",
       "    10    18    32  ...     29    22    19\n",
       "     5     7     7  ...     21    25    33\n",
       "    16    16     5  ...     14    24     1\n",
       "        ...          ⋱          ...       \n",
       "     4    15    14  ...      7    35    32\n",
       "    23     6    34  ...      9    18    21\n",
       "    36    34    12  ...     23    30    13\n",
       " [torch.cuda.LongTensor of size 37x3200 (GPU 0)])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P[:, 0, 1], A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.zeros(1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "1.00000e-40 *\n",
       "  1.0000\n",
       "[torch.DoubleTensor of size 1]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z + 1e-40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "        count_gt = c.view(-1)\n",
    "        indicator = Variable(torch.zeros(B, k))\n",
    "        if USE_CUDA:\n",
    "            indicator = indicator.cuda()\n",
    "        indicator = indicator.scatter(1, count_gt[:, None].long(), 1)  # (B, k)\n",
    "        not_select = indicator.cumsum(dim=1)  # (B, k)\n",
    "        select = 1 - not_select  # (B, k)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #########  HACK ############\n",
    "        count_gt = count_gt.view(-1)\n",
    "        indicator = Variable(torch.zeros(B, k))\n",
    "        if USE_CUDA:\n",
    "            indicator = indicator.cuda()\n",
    "        indicator = indicator.scatter(1, count_gt[:, None].long(), 1)  # (B, k)\n",
    "        not_select = indicator.cumsum(dim=1)  # (B, k)\n",
    "        select = 1 - not_select  # (B, k)\n",
    "\n",
    "        v_emb[:, :, 0] = select.float()\n",
    "\n",
    "        # print(\"count_gt = \", count_gt)\n",
    "        # print(\"indicator = \", indicator)\n",
    "        # print(\"select = \", select)\n",
    "        # raise Exception(\"hoopla\")\n",
    "        ###########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "  9.9070e-01  1.0466e+00  3.0018e-01  ...   1.0486e-03 -1.0895e-02 -2.6854e-03\n",
       "  1.0868e+00  1.0649e+00  1.1275e+00  ...  -1.2944e-03 -6.8956e-03 -1.3778e-03\n",
       "  1.0535e+00  1.1431e+00  8.1334e-01  ...  -1.3563e-02 -5.1921e-03  2.6299e-02\n",
       "                 ...                   ⋱                   ...                \n",
       "  1.0174e+00  9.0691e-01  9.7639e-01  ...  -1.0598e-03  1.4735e-03  1.5625e-02\n",
       "  1.1298e+00  8.8190e-01  1.0423e+00  ...  -5.7358e-03  1.9252e-02  3.8303e-03\n",
       "  8.6857e-01  4.6882e-02  2.1066e-03  ...   1.5766e-02 -1.9883e-03 -5.3849e-03\n",
       " [torch.cuda.FloatTensor of size 50x36 (GPU 0)], Variable containing:\n",
       "     1     1     0  ...      0     0     0\n",
       "     1     1     1  ...      0     0     0\n",
       "     1     1     1  ...      0     0     0\n",
       "        ...          ⋱          ...       \n",
       "     1     1     1  ...      0     0     0\n",
       "     1     1     1  ...      0     0     0\n",
       "     1     0     0  ...      0     0     0\n",
       " [torch.cuda.FloatTensor of size 50x36 (GPU 0)])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kappa_0, select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #########  HACK ############\n",
    "        count_gt = count_gt.view(-1)\n",
    "        indicator = Variable(torch.zeros(B, k))\n",
    "        if USE_CUDA:\n",
    "            indicator = indicator.cuda()\n",
    "        indicator = indicator.scatter(1, count_gt[:, None].long(), 1)  # (B, k)\n",
    "        not_select = indicator.cumsum(dim=1)  # (B, k)\n",
    "        select = 1 - not_select  # (B, k)\n",
    "\n",
    "        v_emb[:, :, 0] = select.float()\n",
    "\n",
    "        # print(\"count_gt = \", count_gt)\n",
    "        # print(\"indicator = \", indicator)\n",
    "        # print(\"select = \", select)\n",
    "        # raise Exception(\"hoopla\")\n",
    "        ###########################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
